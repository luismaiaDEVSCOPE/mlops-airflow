{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec650bf3-13bc-44ee-836d-0b95ec552b9d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Class II: Infrastructure as Code for MLOps\n",
    "\n",
    "## üå± Project: Bonsai Species Classifier for Plant E-commerce\n",
    "\n",
    "Welcome to our hands-on MLOps session! We're building a **bonsai species classifier** for a plant website that will:\n",
    "- **Identify bonsai species** from plant measurements\n",
    "- **Provide care recommendations** based on species type\n",
    "- **Help customers** choose the right bonsai for their needs\n",
    "\n",
    "### Infrastructure Stack (All Containerized!)\n",
    "- **MLflow**: For experiment tracking and model registry\n",
    "- **Docker**: All services are containerized (no local installation needed!)\n",
    "- **JupyterLab**: You're running this from a container right now\n",
    "- **API**: Model serving for the plant website\n",
    "\n",
    "## Quick Setup Check\n",
    "Make sure all containers are running:\n",
    "- MLflow UI: http://localhost:5000 (track bonsai model experiments)\n",
    "- JupyterLab: http://localhost:8888 (you're here!)\n",
    "- API: http://localhost:8080 (bonsai species prediction service)\n",
    "\n",
    "Let's start building our bonsai classifier! üå≥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288238e6-cdf0-4abc-9895-f69ec8c0a48d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First, let's install MLflow in this container and set up the connection\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Install MLflow if not already installed\n",
    "try:\n",
    "    import mlflow\n",
    "    print(\"‚úÖ MLflow already installed\")\n",
    "except ImportError:\n",
    "    print(\"üì¶ Installing MLflow...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"mlflow\"])\n",
    "    import mlflow\n",
    "\n",
    "# Set the MLflow tracking URI to connect to our containerized MLflow server\n",
    "import os\n",
    "os.environ['MLFLOW_TRACKING_URI'] = 'http://mlflow:5000'\n",
    "mlflow.set_tracking_uri('http://mlflow:5000')\n",
    "\n",
    "print(f\"üéØ MLflow Tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "print(\"üöÄ Ready to track experiments!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a3cf23-bcec-4a0b-80a8-f798fab5963d",
   "metadata": {},
   "source": [
    "# üå≥ Bonsai Species Classification with MLflow\n",
    "\n",
    "Now let's train our bonsai species classifier and track the experiment. We'll classify 4 types of bonsai:\n",
    "- **Juniper Bonsai** (0): Hardy, needle-like foliage\n",
    "- **Ficus Bonsai** (1): Broad leaves, aerial roots  \n",
    "- **Pine Bonsai** (2): Long needles, rugged bark\n",
    "- **Maple Bonsai** (3): Distinctive lobed leaves\n",
    "\n",
    "We'll track:\n",
    "- **Parameters**: Model configuration (n_estimators, etc.)\n",
    "- **Metrics**: Classification performance (accuracy, etc.)\n",
    "- **Artifacts**: The trained bonsai classifier model\n",
    "\n",
    "Check the MLflow UI at http://localhost:5000 to see your bonsai classification experiments! üå±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf84929f-7656-41ae-8884-b277102570c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.sklearn\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a simulated bonsai dataset (replacing Iris for our bonsai classifier)\n",
    "# Features: leaf_length, leaf_width, branch_thickness, height\n",
    "X, y = make_classification(\n",
    "    n_samples=300,\n",
    "    n_features=4,\n",
    "    n_classes=4,\n",
    "    n_informative=4,\n",
    "    n_redundant=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Add realistic feature names and scaling for bonsai measurements\n",
    "feature_names = ['leaf_length_cm', 'leaf_width_cm', 'branch_thickness_mm', 'height_cm']\n",
    "bonsai_species = ['Juniper', 'Ficus', 'Pine', 'Maple']\n",
    "\n",
    "# Scale features to realistic bonsai measurements\n",
    "X[:, 0] = X[:, 0] * 0.5 + 2.0  # leaf_length: 1.5-2.5 cm\n",
    "X[:, 1] = X[:, 1] * 0.3 + 1.5  # leaf_width: 1.2-1.8 cm\n",
    "X[:, 2] = X[:, 2] * 2.0 + 5.0  # branch_thickness: 3-7 mm\n",
    "X[:, 3] = X[:, 3] * 10.0 + 25.0  # height: 15-35 cm\n",
    "\n",
    "# Create DataFrame for better visualization\n",
    "bonsai_df = pd.DataFrame(X, columns=feature_names)\n",
    "bonsai_df['species'] = [bonsai_species[i] for i in y]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"üå± Bonsai Dataset created:\")\n",
    "print(f\"Training samples: {X_train.shape[0]}\")\n",
    "print(f\"Test samples: {X_test.shape[0]}\")\n",
    "print(f\"Features: {feature_names}\")\n",
    "print(f\"Species classes: {bonsai_species}\")\n",
    "\n",
    "# Show sample data\n",
    "print(\"\\nüìä Sample bonsai measurements:\")\n",
    "print(bonsai_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87059b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start MLflow experiment tracking for bonsai classification\n",
    "mlflow.set_experiment(\"Bonsai-Species-Classification\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # Model parameters\n",
    "    n_estimators = 100\n",
    "    max_depth = 3\n",
    "    \n",
    "    # Train the bonsai classifier\n",
    "    bonsai_classifier = RandomForestClassifier(\n",
    "        n_estimators=n_estimators, \n",
    "        max_depth=max_depth,\n",
    "        random_state=42\n",
    "    )\n",
    "    bonsai_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    preds = bonsai_classifier.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    \n",
    "    # Log parameters to MLflow\n",
    "    mlflow.log_param('n_estimators', n_estimators)\n",
    "    mlflow.log_param('max_depth', max_depth)\n",
    "    mlflow.log_param('model_type', 'RandomForestClassifier')\n",
    "    mlflow.log_param('dataset', 'Bonsai Species')\n",
    "    mlflow.log_param('n_species', len(bonsai_species))\n",
    "    \n",
    "    # Log metrics to MLflow\n",
    "    mlflow.log_metric('accuracy', acc)\n",
    "    mlflow.log_metric('test_samples', len(y_test))\n",
    "    \n",
    "    # Log the trained bonsai classifier directly as an MLflow artifact\n",
    "    mlflow.sklearn.log_model(bonsai_classifier, name=\"bonsai_classifier\")\n",
    "    \n",
    "    print(f'\\n‚úÖ Bonsai classifier trained!')\n",
    "    print(f'üéØ Accuracy: {acc:.3f}')\n",
    "    print(f'üå≥ Species classified: {bonsai_species}')\n",
    "    print(f'üìù Experiment logged to MLflow')\n",
    "    print(f'üåê View at: http://localhost:5000')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9d4caf-2d7c-4e71-930c-72e764148d5f",
   "metadata": {},
   "source": [
    "# üå± Bonsai Model Registry\n",
    "\n",
    "Now let's register our best bonsai classifier in the MLflow Model Registry. This allows us to:\n",
    "- **Version our bonsai models** as we improve them\n",
    "- **Promote models through stages** (Staging ‚Üí Production) for the plant website\n",
    "- **Track model lineage and metadata** for different bonsai classification approaches\n",
    "\n",
    "The Model Registry is like a \"model store\" for the plant e-commerce website.\n",
    "\n",
    "**Note**: First, let's check if our MLflow server supports Model Registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736fb7c5-989b-42bc-9c90-ece706d3cb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the bonsai classifier in MLflow Model Registry\n",
    "model_name = 'Bonsai-Species-Classifier-Production'\n",
    "\n",
    "# Let's train a better bonsai classifier for the plant website\n",
    "with mlflow.start_run():\n",
    "    # Improved hyperparameters for better bonsai classification\n",
    "    n_estimators = 200\n",
    "    max_depth = 6\n",
    "    min_samples_split = 3\n",
    "    \n",
    "    bonsai_classifier = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        random_state=42\n",
    "    )\n",
    "    bonsai_classifier.fit(X_train, y_train)\n",
    "    preds = bonsai_classifier.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    \n",
    "    # Log everything for the bonsai model\n",
    "    mlflow.log_param('n_estimators', n_estimators)\n",
    "    mlflow.log_param('max_depth', max_depth)\n",
    "    mlflow.log_param('min_samples_split', min_samples_split)\n",
    "    mlflow.log_param('model_purpose', 'Plant E-commerce Website')\n",
    "    mlflow.log_metric('accuracy', acc)\n",
    "    \n",
    "    # Log and register the bonsai classifier\n",
    "    mlflow.sklearn.log_model(\n",
    "        bonsai_classifier, \n",
    "        name='bonsai_classifier',\n",
    "        registered_model_name=model_name\n",
    "    )\n",
    "    \n",
    "    print(f'‚úÖ Bonsai classifier trained and logged!')\n",
    "    print(f'üéØ Accuracy: {acc:.3f}')\n",
    "    print(f'üå≥ Model registered: {model_name}')\n",
    "    print(f'ÔøΩ Go to MLflow UI ‚Üí Models tab to promote to Production!')\n",
    "    print(f'üåê http://localhost:5000/#/models/{model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f594b75-508e-453a-8a4f-969916d969e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Promote bonsai classifier to Production (typical MLOps workflow for plant website)\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "try:\n",
    "    client = MlflowClient()\n",
    "    \n",
    "    # Check if bonsai model exists\n",
    "    try:\n",
    "        model_info = client.get_registered_model(model_name)\n",
    "        print(f'üì¶ Found bonsai model: {model_name}')\n",
    "    except:\n",
    "        print(f'‚ùå Bonsai model {model_name} not found in registry')\n",
    "        print('üí° Please run the previous cell to register the bonsai model first')\n",
    "        raise\n",
    "    \n",
    "    # Get the latest version\n",
    "    model_versions = client.get_latest_versions(model_name)\n",
    "    if not model_versions:\n",
    "        print(f'‚ùå No versions found for bonsai model {model_name}')\n",
    "        raise Exception(\"No bonsai model versions available\")\n",
    "    \n",
    "    latest_version = model_versions[0].version\n",
    "    print(f'üîç Latest bonsai model version: {latest_version}')\n",
    "    \n",
    "    # Transition to Staging first (for plant website testing)\n",
    "    client.transition_model_version_stage(\n",
    "        name=model_name,\n",
    "        version=latest_version,\n",
    "        stage=\"Staging\"\n",
    "    )\n",
    "    print(f'üìã Version {latest_version} moved to Staging for plant website testing')\n",
    "    \n",
    "    # After review, promote to Production (live plant website)\n",
    "    client.transition_model_version_stage(\n",
    "        name=model_name,\n",
    "        version=latest_version,\n",
    "        stage=\"Production\"\n",
    "    )\n",
    "    print(f'üöÄ Version {latest_version} promoted to Production!')\n",
    "    print(f'‚úÖ Bonsai classifier ready for the plant website!')\n",
    "    print(f'ÔøΩ Check MLflow UI: http://localhost:5000/#/models/{model_name}')\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f'‚ö†Ô∏è Bonsai model promotion failed: {e}')\n",
    "    print('ÔøΩ Possible solutions:')\n",
    "    print('   1. Make sure MLflow server is running')\n",
    "    print('   2. Register a bonsai model first (run previous cells)')\n",
    "    print('   3. Check MLflow UI for registered models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca1faae-8ce4-4269-ada4-9921e66cf017",
   "metadata": {},
   "source": [
    "# üå≥ Testing Our Bonsai Classification API\n",
    "\n",
    "Finally, let's test our bonsai species prediction API! The API is running at http://localhost:8080\n",
    "\n",
    "**Important**: Before testing, go to the MLflow UI and promote your bonsai model to \"Production\" stage:\n",
    "1. Go to http://localhost:5000\n",
    "2. Click \"Models\" tab\n",
    "3. Click on \"Bonsai-Species-Classifier-Production\"\n",
    "4. Click \"Stage Transition\" ‚Üí \"Production\"\n",
    "\n",
    "This API will help customers identify bonsai species on the plant website! üå±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42bbbe2-93b7-41d8-a79b-cfb6fe5a6913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Promote model to Production (typical MLOps workflow)\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "try:\n",
    "    client = MlflowClient()\n",
    "    \n",
    "    # Check if model exists\n",
    "    try:\n",
    "        model_info = client.get_registered_model(model_name)\n",
    "        print(f'üì¶ Found model: {model_name}')\n",
    "    except:\n",
    "        print(f'‚ùå Model {model_name} not found in registry')\n",
    "        print('üí° Please run the previous cell to register the model first')\n",
    "        raise\n",
    "    \n",
    "    # Get the latest version\n",
    "    model_versions = client.get_latest_versions(model_name)\n",
    "    if not model_versions:\n",
    "        print(f'‚ùå No versions found for model {model_name}')\n",
    "        raise Exception(\"No model versions available\")\n",
    "    \n",
    "    latest_version = model_versions[0].version\n",
    "    print(f'üîç Latest version: {latest_version}')\n",
    "    \n",
    "    # Transition to Staging first\n",
    "    client.transition_model_version_stage(\n",
    "        name=model_name,\n",
    "        version=latest_version,\n",
    "        stage=\"Staging\"\n",
    "    )\n",
    "    print(f'üìã Version {latest_version} moved to Staging')\n",
    "    \n",
    "    # After review, promote to Production\n",
    "    client.transition_model_version_stage(\n",
    "        name=model_name,\n",
    "        version=latest_version,\n",
    "        stage=\"Production\"\n",
    "    )\n",
    "    print(f'üöÄ Version {latest_version} promoted to Production!')\n",
    "    print(f'‚úÖ Ready for inference!')\n",
    "    print(f'üåê Check MLflow UI: http://localhost:5000/#/models/{model_name}')\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f'‚ö†Ô∏è Model promotion failed: {e}')\n",
    "    print('üí° Possible solutions:')\n",
    "    print('   1. Make sure MLflow server is running')\n",
    "    print('   2. Register a model first (run previous cells)')\n",
    "    print('   3. Check MLflow UI for registered models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b242a77-e181-41ba-af0d-5325b09e9489",
   "metadata": {},
   "source": [
    "# Testing Our API\n",
    "\n",
    "Finally, let's test our model-serving API! The API is running at http://localhost:8080\n",
    "\n",
    "**Important**: Before testing, go to the MLflow UI and promote your model to \"Production\" stage:\n",
    "1. Go to http://localhost:5000\n",
    "2. Click \"Models\" tab\n",
    "3. Click on \"Bonsai-Species-Classification\"\n",
    "4. Click \"Stage Transition\" ‚Üí \"Production\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a317bf1f-781a-4ecc-b4aa-2e534176c527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing our bonsai classification API...\n",
      "============================================================\n",
      "‚ùå Error: 500 - {\"detail\":\"Prediction error: 'DecisionTreeClassifier' object has no attribute 'monotonic_cst'\"}\n",
      "----------------------------------------\n",
      "‚ùå Error: 500 - {\"detail\":\"Prediction error: 'DecisionTreeClassifier' object has no attribute 'monotonic_cst'\"}\n",
      "----------------------------------------\n",
      "‚ùå Error: 500 - {\"detail\":\"Prediction error: 'DecisionTreeClassifier' object has no attribute 'monotonic_cst'\"}\n",
      "----------------------------------------\n",
      "‚ùå Error: 500 - {\"detail\":\"Prediction error: 'DecisionTreeClassifier' object has no attribute 'monotonic_cst'\"}\n",
      "----------------------------------------\n",
      "üéâ That's MLOps for a Plant E-commerce Website!\n",
      "üìä Experiment tracking ‚úì\n",
      "üìù Model registry ‚úì\n",
      "üöÄ Containerized bonsai classification API ‚úì\n",
      "üå± Ready to help customers identify their bonsai! ‚úì\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Test data - realistic bonsai measurements for different species\n",
    "bonsai_test_cases = [\n",
    "    {\n",
    "        \"name\": \"Juniper Bonsai (should predict 0)\",\n",
    "        \"features\": [1.8, 1.3, 4.2, 22.0],  # Small leaves, thin branches\n",
    "        \"description\": \"Hardy evergreen with needle-like foliage\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Ficus Bonsai (should predict 1)\", \n",
    "        \"features\": [2.3, 1.7, 6.1, 28.5],  # Broader leaves, thicker trunk\n",
    "        \"description\": \"Broad leaves with aerial root potential\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Pine Bonsai (should predict 2)\",\n",
    "        \"features\": [2.1, 1.2, 5.8, 31.2],  # Long needles, moderate thickness\n",
    "        \"description\": \"Classic pine with distinctive needle clusters\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Maple Bonsai (should predict 3)\",\n",
    "        \"features\": [2.4, 1.9, 5.2, 26.8],  # Distinctive lobed leaves\n",
    "        \"description\": \"Beautiful seasonal color changes\"\n",
    "    }\n",
    "]\n",
    "\n",
    "api_url = \"http://api:8080/predict\"  # Using container name\n",
    "# If that doesn't work, try: api_url = \"http://localhost:8080/predict\"\n",
    "\n",
    "print(\"üß™ Testing our bonsai classification API...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for test_case in bonsai_test_cases:\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            api_url,\n",
    "            json={\"features\": test_case[\"features\"]},\n",
    "            timeout=10\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            prediction = response.json()[\"prediction\"]\n",
    "            species_name = bonsai_species[prediction]\n",
    "            print(f\"‚úÖ {test_case['name']}\")\n",
    "            print(f\"   Measurements: {test_case['features']}\")\n",
    "            print(f\"   üå≥ Predicted: {prediction} ({species_name})\")\n",
    "            print(f\"   üìù {test_case['description']}\")\n",
    "        else:\n",
    "            print(f\"‚ùå Error: {response.status_code} - {response.text}\")\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"‚ùå Connection error: {e}\")\n",
    "        print(\"üí° Make sure the API container is running!\")\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "\n",
    "print(\"üéâ That's MLOps for a Plant E-commerce Website!\")\n",
    "print(\"üìä Experiment tracking ‚úì\")\n",
    "print(\"üìù Model registry ‚úì\") \n",
    "print(\"üöÄ Containerized bonsai classification API ‚úì\")\n",
    "print(\"üå± Ready to help customers identify their bonsai! ‚úì\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f09236d-cb99-4b84-bea3-6b8c6f7f94bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
