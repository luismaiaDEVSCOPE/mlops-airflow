{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a372eb0",
   "metadata": {},
   "source": [
    "# Class II: Deep-dive into MLOps & Infrastructure\n",
    "\n",
    "Welcome to our hands-on MLOps session! In this notebook, we'll work with:\n",
    "- **MLflow**: For experiment tracking and model registry\n",
    "- **Docker**: All services are containerized (no local installation needed!)\n",
    "- **JupyterLab**: You're running this from a container right now\n",
    "\n",
    "## Quick Setup Check\n",
    "Make sure all containers are running:\n",
    "- MLflow UI: http://localhost:5000\n",
    "- JupyterLab: http://localhost:8888 (you're here!)\n",
    "- API: http://localhost:8080\n",
    "\n",
    "Let's start with experiment tracking!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd16c18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's install MLflow in this container and set up the connection\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Install MLflow if not already installed\n",
    "try:\n",
    "    import mlflow\n",
    "    print(\"‚úÖ MLflow already installed\")\n",
    "except ImportError:\n",
    "    print(\"üì¶ Installing MLflow...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"mlflow\"])\n",
    "    import mlflow\n",
    "\n",
    "# Set the MLflow tracking URI to connect to our containerized MLflow server\n",
    "import os\n",
    "os.environ['MLFLOW_TRACKING_URI'] = 'http://mlflow:5000'\n",
    "mlflow.set_tracking_uri('http://mlflow:5000')\n",
    "\n",
    "print(f\"üéØ MLflow Tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "print(\"üöÄ Ready to track experiments!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c49f15d",
   "metadata": {},
   "source": [
    "# Experiment Tracking with MLflow\n",
    "\n",
    "Now let's train a model and track the experiment. We'll log:\n",
    "- **Parameters**: Model configuration (n_estimators, etc.)\n",
    "- **Metrics**: Performance metrics (accuracy, etc.)\n",
    "- **Artifacts**: The trained model itself\n",
    "\n",
    "Check the MLflow UI at http://localhost:5000 to see your experiments!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7963e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"üìä Dataset loaded:\")\n",
    "print(f\"Training samples: {X_train.shape[0]}\")\n",
    "print(f\"Test samples: {X_test.shape[0]}\")\n",
    "print(f\"Features: {X_train.shape[1]}\")\n",
    "print(f\"Classes: {iris.target_names}\")\n",
    "\n",
    "# Start MLflow experiment tracking\n",
    "with mlflow.start_run():\n",
    "    # Model parameters\n",
    "    n_estimators = 100\n",
    "    max_depth = 3\n",
    "    \n",
    "    # Train the model\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=n_estimators, \n",
    "        max_depth=max_depth,\n",
    "        random_state=42\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    preds = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    \n",
    "    # Log parameters to MLflow\n",
    "    mlflow.log_param('n_estimators', n_estimators)\n",
    "    mlflow.log_param('max_depth', max_depth)\n",
    "    mlflow.log_param('model_type', 'RandomForestClassifier')\n",
    "    \n",
    "    # Log metrics to MLflow\n",
    "    mlflow.log_metric('accuracy', acc)\n",
    "    mlflow.log_metric('test_samples', len(y_test))\n",
    "    \n",
    "    # Log the trained model directly as an MLflow artifact (no manual file creation needed)\n",
    "    mlflow.sklearn.log_model(clf, artifact_path=\"model\")\n",
    "    \n",
    "    print(f'‚úÖ Model trained!')\n",
    "    print(f'üéØ Accuracy: {acc:.3f}')\n",
    "    print(f'üìù Experiment logged to MLflow')\n",
    "    print(f'üåê View at: http://localhost:5000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1114dca8-dada-4e56-b91f-23529a08fe07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "343f3ae9",
   "metadata": {},
   "source": [
    "# Model Registry\n",
    "\n",
    "Now let's register our best model in the MLflow Model Registry. This allows us to:\n",
    "- Version our models\n",
    "- Promote models through stages (Staging ‚Üí Production)\n",
    "- Track model lineage and metadata\n",
    "\n",
    "The Model Registry is like a \"model store\" for your organization.\n",
    "\n",
    "**Note**: First, let's check if our MLflow server supports Model Registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503205df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check MLflow server connectivity and Model Registry availability\n",
    "import requests\n",
    "\n",
    "try:\n",
    "    # Test basic MLflow server connectivity\n",
    "    response = requests.get('http://mlflow:5000/health', timeout=5)\n",
    "    if response.status_code == 200:\n",
    "        print(\"‚úÖ MLflow server is running\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è MLflow server response: {response.status_code}\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"‚ùå Cannot connect to MLflow server: {e}\")\n",
    "    print(\"üí° Make sure MLflow container is running: docker-compose up -d\")\n",
    "\n",
    "# Test Model Registry API endpoint\n",
    "try:\n",
    "    response = requests.get('http://mlflow:5000/api/2.0/mlflow/registered-models/list', timeout=5)\n",
    "    if response.status_code == 200:\n",
    "        print(\"‚úÖ Model Registry is available\")\n",
    "        models = response.json()\n",
    "        print(f\"üìã Registered models: {len(models.get('registered_models', []))}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Model Registry response: {response.status_code}\")\n",
    "        print(\"üí° This might be expected if no models are registered yet\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"‚ùå Model Registry not accessible: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43257d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the model in MLflow Model Registry with error handling\n",
    "model_name = 'Iris-RandomForest-Best'\n",
    "\n",
    "# Let's train a slightly better model for registration\n",
    "with mlflow.start_run():\n",
    "    # Better hyperparameters\n",
    "    n_estimators = 150\n",
    "    max_depth = 5\n",
    "    \n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        random_state=42\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "    preds = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    \n",
    "    # Log everything\n",
    "    mlflow.log_param('n_estimators', n_estimators)\n",
    "    mlflow.log_param('max_depth', max_depth)\n",
    "    mlflow.log_metric('accuracy', acc)\n",
    "    \n",
    "    # Log and register the model (should work now with fixed permissions)\n",
    "    mlflow.sklearn.log_model(\n",
    "        clf, \n",
    "        'model',\n",
    "        registered_model_name=model_name\n",
    "    )\n",
    "    \n",
    "    print(f'‚úÖ Model trained and logged!')\n",
    "    print(f'üéØ Accuracy: {acc:.3f}')\n",
    "    print(f' Model registered: {model_name}')\n",
    "    print(f'üìã Go to MLflow UI ‚Üí Models tab to promote to Production!')\n",
    "    print(f'üåê http://localhost:5000/#/models/{model_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7883b9",
   "metadata": {},
   "source": [
    "# Model Promotion Workflow\n",
    "\n",
    "Once a model is registered, we typically move it through different stages:\n",
    "\n",
    "1. **None** ‚Üí **Staging** ‚Üí **Production**\n",
    "2. This allows for testing and validation before production deployment\n",
    "3. Multiple versions can exist in different stages simultaneously\n",
    "\n",
    "Let's promote our best model to Production stage!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a911e594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Promote model to Production (typical MLOps workflow)\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "try:\n",
    "    client = MlflowClient()\n",
    "    \n",
    "    # Check if model exists\n",
    "    try:\n",
    "        model_info = client.get_registered_model(model_name)\n",
    "        print(f'üì¶ Found model: {model_name}')\n",
    "    except:\n",
    "        print(f'‚ùå Model {model_name} not found in registry')\n",
    "        print('üí° Please run the previous cell to register the model first')\n",
    "        raise\n",
    "    \n",
    "    # Get the latest version\n",
    "    model_versions = client.get_latest_versions(model_name, stages=[\"None\"])\n",
    "    if not model_versions:\n",
    "        print(f'‚ùå No versions found for model {model_name}')\n",
    "        raise Exception(\"No model versions available\")\n",
    "    \n",
    "    latest_version = model_versions[0].version\n",
    "    print(f'üîç Latest version: {latest_version}')\n",
    "    \n",
    "    # Transition to Staging first\n",
    "    client.transition_model_version_stage(\n",
    "        name=model_name,\n",
    "        version=latest_version,\n",
    "        stage=\"Staging\"\n",
    "    )\n",
    "    print(f'üìã Version {latest_version} moved to Staging')\n",
    "    \n",
    "    # After review, promote to Production\n",
    "    client.transition_model_version_stage(\n",
    "        name=model_name,\n",
    "        version=latest_version,\n",
    "        stage=\"Production\"\n",
    "    )\n",
    "    print(f'üöÄ Version {latest_version} promoted to Production!')\n",
    "    print(f'‚úÖ Ready for inference!')\n",
    "    print(f'üåê Check MLflow UI: http://localhost:5000/#/models/{model_name}')\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f'‚ö†Ô∏è Model promotion failed: {e}')\n",
    "    print('üí° Possible solutions:')\n",
    "    print('   1. Make sure MLflow server is running')\n",
    "    print('   2. Register a model first (run previous cells)')\n",
    "    print('   3. Check MLflow UI for registered models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc85879",
   "metadata": {},
   "source": [
    "# Testing Our API\n",
    "\n",
    "Finally, let's test our model-serving API! The API is running at http://localhost:8080\n",
    "\n",
    "**Important**: Before testing, go to the MLflow UI and promote your model to \"Production\" stage:\n",
    "1. Go to http://localhost:5000\n",
    "2. Click \"Models\" tab\n",
    "3. Click on \"Iris-RandomForest-Best\"\n",
    "4. Click \"Stage Transition\" ‚Üí \"Production\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fab578e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Test data - these are actual Iris flower measurements\n",
    "test_cases = [\n",
    "    {\n",
    "        \"name\": \"Setosa (should predict 0)\",\n",
    "        \"features\": [5.1, 3.5, 1.4, 0.2]  # Typical Setosa measurements\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Versicolor (should predict 1)\", \n",
    "        \"features\": [6.0, 2.7, 4.8, 1.4]  # Typical Versicolor measurements\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Virginica (should predict 2)\",\n",
    "        \"features\": [7.2, 3.6, 6.1, 2.5]  # Typical Virginica measurements\n",
    "    }\n",
    "]\n",
    "\n",
    "api_url = \"http://api:8080/predict\"  # Using container name\n",
    "# If that doesn't work, try: api_url = \"http://localhost:8080/predict\"\n",
    "\n",
    "print(\"üß™ Testing our containerized ML API...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for test_case in test_cases:\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            api_url,\n",
    "            json={\"features\": test_case[\"features\"]},\n",
    "            timeout=10\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            prediction = response.json()[\"prediction\"]\n",
    "            class_name = iris.target_names[prediction]\n",
    "            print(f\"‚úÖ {test_case['name']}\")\n",
    "            print(f\"   Features: {test_case['features']}\")\n",
    "            print(f\"   Prediction: {prediction} ({class_name})\")\n",
    "        else:\n",
    "            print(f\"‚ùå Error: {response.status_code} - {response.text}\")\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"‚ùå Connection error: {e}\")\n",
    "        print(\"üí° Make sure the API container is running!\")\n",
    "    \n",
    "    print(\"-\" * 30)\n",
    "\n",
    "print(\"üéâ That's MLOps in action!\")\n",
    "print(\"üìä Experiment tracking ‚úì\")\n",
    "print(\"üìù Model registry ‚úì\") \n",
    "print(\"üöÄ Containerized API ‚úì\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
